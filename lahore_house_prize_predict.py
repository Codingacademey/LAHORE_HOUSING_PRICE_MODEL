# -*- coding: utf-8 -*-
"""lahore_house_prize_predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tNkoMA6tAyC6M6cbiy7zGrvSYb3_a5uv
"""

import pandas as pd
import numpy as np

df=pd.read_csv('lahore.csv')

df.head()

for i in df.columns:
  print(df[i].value_counts())
  print('*'*20)

df.isnull().sum()

df.head()

df.drop(columns=["house_id"],inplace=True)

df["Type"].value_counts()

df=df[~df['Type'].isin(['Penthouse', 'Room'])]

df.head()

df["Location"].value_counts()

value=df["Location"].value_counts()
value_less_10=value[value<10]

df["Location"]=df["Location"].apply(lambda x: 'others' if x in value_less_10 else x)

df["Location"].value_counts()

df['Area'].value_counts()

def func(x):
  num, unit = x.split()
  num = float(num)
  if unit.lower() == "marla":
    return num* 272.25
  if unit.lower() == "kanal":
    return num* 5445
  else :
    return num

df['Area']=df["Area"].apply(func)

def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df[(df[column] >= lower) & (df[column] <= upper)]
df = remove_outliers_iqr(df, 'Price')

df.head()

df.describe()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.histplot(df["Price"], kde=True)
plt.title("Distribution of Housing Prices")
plt.show()

df["Price"]

plt.figure(figsize=(8,5))
sns.histplot(np.reciprocal(df["Price"]), kde=True)
plt.title("Distribution of Housing Prices")
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(np.sqrt(df["Price"]), kde=True)
plt.title("Distribution of Housing Prices")
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(np.log1p(df["Price"]), kde=True)
plt.title("Distribution of Housing Prices")
plt.show()

df['Price'] = np.log1p(df['Price'])

df['Price'].skew()

sns.scatterplot(x="Bath(s)",y="Price",data=df)

df.describe()

df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

X=df.drop(columns=["Price"])
y=df["Price"]

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

col_trans=ColumnTransformer([("passthrough",OneHotEncoder(sparse_output=False),["Location","Type"])],remainder="passthrough")

scaler=StandardScaler()

lr=XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6, random_state=0)

pipe=make_pipeline(col_trans,scaler,lr)

pipe.fit(X_train,y_train)

y_pred=pipe.predict(X_test)

r2_score(y_test,y_pred)

import pickle

pickle.dump(pipe,open('pipe.pkl','wb'))

import joblib
joblib.dump(pipe, 'model.joblib')

